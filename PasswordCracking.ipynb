{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PasswordCracking.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"HArYSNOmo2z-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":141},"outputId":"b5d1f578-b7dd-43d8-dfb5-5cf02ce68b4e","executionInfo":{"status":"ok","timestamp":1550168795968,"user_tz":-330,"elapsed":39861,"user":{"displayName":"Nishant Raj","photoUrl":"https://lh4.googleusercontent.com/-NHtdm8K9_Dg/AAAAAAAAAAI/AAAAAAAAYKw/NSp19mVFAtw/s64/photo.jpg","userId":"05931898844418143698"}}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","import os\n","os.chdir ('/content/drive/My Drive')\n","print(os.listdir('/content/drive/My Drive/datasets'))"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n","['testhash.csv', 'trainhash.csv']\n"],"name":"stdout"}]},{"metadata":{"id":"kdt9YfuwsJQz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1076},"outputId":"971aa448-3a74-464b-be00-9294d668bc56","executionInfo":{"status":"ok","timestamp":1550169843223,"user_tz":-330,"elapsed":24935,"user":{"displayName":"Nishant Raj","photoUrl":"https://lh4.googleusercontent.com/-NHtdm8K9_Dg/AAAAAAAAAAI/AAAAAAAAYKw/NSp19mVFAtw/s64/photo.jpg","userId":"05931898844418143698"}}},"cell_type":"code","source":["import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","import numpy as np\n","\n","import csv\n","\n","h_train = []\n","l_train = []\n","path = '/content/drive/My Drive/datasets/'\n","print('Started!')\n","print('Data loading started\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/')\n","i=0\n","with open(path+'trainhash.csv') as myFile:\n","    reader = csv.DictReader(myFile)\n","    for row in reader:\n","        # if(i==5):\n","        #     break\n","        # print(row['hash'])\n","        # i += 1\n","        re = str(bin(int(row['hash'], 16)))[2:]\n","\n","        while(len(re) != 256):\n","            re = '0'+ re\n","\n","        h_train.append(np.array(list(re)))\n","        # l_train.append(row['len'])\n","# print(h_train[0].shape)\n","# for i in range(0,5):\n","#     print(h_train[i].shape)\n","        datalen = int(row['len'])-1\n","        l_train.append(datalen)\n","        # if(num_classes < datalen):\n","        #     num_classes = datalen\n","\n","\n","h_train = np.array(h_train)\n","l_train = np.array(l_train)\n","print('Training data loaded.\\nTraining size is {}'.format(h_train[0].shape[0]))\n","\n","h_test = []\n","l_test = []\n","\n","num_classes = 0\n","\n","with open(path+'testhash.csv') as myFile:\n","    reader = csv.DictReader(myFile)\n","    for row in reader:\n","        # print(row['hash'])\n","        re = str(bin(int(row['hash'], 16)))[2:]\n","\n","        while (len(re) != 256):\n","            re = '0' + re\n","\n","        h_test.append(np.array(list(re)))\n","\n","        # h_test.append(list(str(bin(int(row['hash'], 16)))[2:]))\n","        datalen = int(row['len'])-1\n","        l_test.append(datalen)\n","        if(num_classes < datalen):\n","            num_classes = datalen\n","\n","print('Classes: '+str(num_classes))\n","print(l_test[250])\n","h_test = np.array(h_test)\n","l_test = np.array(l_test)\n","\n","print('Testind data loaded.\\nTesting size is {}'.format(h_test.shape))\n","print('Data is loaded!!\\n Training is started!')\n","\n","batch_size = 128\n","\n","epochs = 12\n","\n","# input image dimensions\n","img_rows, img_cols = 16, 16\n","\n","# the data, split between train and test sets\n","# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","x_train = h_train.reshape(h_train.shape[0],16,16,1)\n","x_test = h_test.reshape(h_test.shape[0],16,16,1)\n","\n","\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","y_train = l_train\n","y_test = l_test\n","\n","num_classes = num_classes + 1\n","\n","# Y = 2 # the value 2 represents that the hash is of input size digit 2\n","#\n","# Y = [0,0,1,0] # The 2nd position in the vector is made 1\n","#\n","# # Here, the class value is converted into a binary class matrix\n","\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","model = Sequential()\n","\n","model.add(Conv2D(32, kernel_size=(3, 3),\n","                 activation='relu',\n","                 input_shape=(16,16,1)))\n","\n","model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","# model.add(Dropout(0.5))\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","model.compile(loss=keras.losses.categorical_crossentropy,\n","              optimizer=keras.optimizers.Adadelta(),\n","              metrics=['accuracy'])\n","\n","model.summary()\n","\n","model.fit(x_train, y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1,\n","          validation_data=(x_test, y_test))\n","\n","score = model.evaluate(x_test, y_test, verbose=0)\n","\n","print('Test loss:', score[0])\n","print('Test accuracy:', 100*score[1],'%')\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Started!\n","Data loading started\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\n","Training data loaded.\n","Training size is 256\n","Classes: 3\n","3\n","Testind data loaded.\n","Testing size is (2500, 256)\n","Data is loaded!!\n"," Training is started!\n","x_train shape: (7500, 16, 16, 1)\n","7500 train samples\n","2500 test samples\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_3 (Conv2D)            (None, 14, 14, 32)        320       \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 12, 12, 64)        18496     \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 2304)              0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 128)               295040    \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 4)                 516       \n","=================================================================\n","Total params: 314,372\n","Trainable params: 314,372\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 7500 samples, validate on 2500 samples\n","Epoch 1/12\n","7500/7500 [==============================] - 2s 285us/step - loss: 0.3967 - acc: 0.8859 - val_loss: 0.3695 - val_acc: 0.9000\n","Epoch 2/12\n","7500/7500 [==============================] - 2s 245us/step - loss: 0.3704 - acc: 0.9000 - val_loss: 0.3866 - val_acc: 0.9000\n","Epoch 3/12\n","7500/7500 [==============================] - 2s 286us/step - loss: 0.3668 - acc: 0.9000 - val_loss: 0.3751 - val_acc: 0.9000\n","Epoch 4/12\n","7500/7500 [==============================] - 2s 244us/step - loss: 0.3677 - acc: 0.9000 - val_loss: 0.3907 - val_acc: 0.9000\n","Epoch 5/12\n","7500/7500 [==============================] - 2s 234us/step - loss: 0.3668 - acc: 0.9000 - val_loss: 0.3736 - val_acc: 0.9000\n","Epoch 6/12\n","7500/7500 [==============================] - 2s 246us/step - loss: 0.3610 - acc: 0.9000 - val_loss: 0.3643 - val_acc: 0.9000\n","Epoch 7/12\n","7500/7500 [==============================] - 2s 248us/step - loss: 0.3608 - acc: 0.9000 - val_loss: 0.3685 - val_acc: 0.9000\n","Epoch 8/12\n","7500/7500 [==============================] - 2s 246us/step - loss: 0.3570 - acc: 0.9000 - val_loss: 0.3637 - val_acc: 0.9000\n","Epoch 9/12\n","7500/7500 [==============================] - 2s 240us/step - loss: 0.3534 - acc: 0.9000 - val_loss: 0.3645 - val_acc: 0.9000\n","Epoch 10/12\n","7500/7500 [==============================] - 2s 244us/step - loss: 0.3459 - acc: 0.9000 - val_loss: 0.4546 - val_acc: 0.9000\n","Epoch 11/12\n","7500/7500 [==============================] - 2s 242us/step - loss: 0.3410 - acc: 0.9000 - val_loss: 0.3728 - val_acc: 0.9000\n","Epoch 12/12\n","7500/7500 [==============================] - 2s 239us/step - loss: 0.3365 - acc: 0.9000 - val_loss: 0.3807 - val_acc: 0.9000\n","Test loss: 0.3806750925064087\n","Test accuracy: 90.0 %\n"],"name":"stdout"}]}]}